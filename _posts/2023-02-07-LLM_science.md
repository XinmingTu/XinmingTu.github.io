---
layout: distill
title: AI for General Science - Large language models for scientific hypothesis/research ideas generation
description:
date: 2023-02-07

authors:
  - name: Xinming Tu
    url: "https://xinmingtu.cn"
    affiliations:
      name: University of Washington
---

## Introduction

Artificial intelligence and machine learning have been making significant advancements in various fields, including science. However, the use of LLMs in the scientific community has been limited to fine-tuning models for specific domains, such as medical question-answering, or revision of existing text. This is due to concerns about the accuracy and reliability of the generated content, as LLMs are known to sometimes generate information that is not supported by existing data or publication.

However, if we approach the use of LLMs differently, and view them not as a source of truth, but rather as a tool for generating new and creative ideas, they have the potential to be extremely valuable in the scientific community. LLMs are not limited by the implicit biases or boundaries of the human mind, and when combined with automated algorithms, they have the potential to generate new and innovative research ideas that may have been missed by scientists working alone.

The process of generating scientific hypotheses and research ideas is a complex and time-consuming task that requires creativity, critical thinking, and a thorough understanding of the field. With the use of LLMs, scientists can access a vast knowledge base and generate new ideas at a much faster rate, potentially leading to new breakthroughs and discoveries.

In this blog, we will explore the potential of using LLMs as a tool for generating scientific hypotheses and research ideas, and the advantages and limitations of this approach.

## Method

In this section, I will give a initial idea about how to use LLMs to generate scientific hypotheses and research ideas.

The process can be broken down into three main steps:

- **Finding keywords and concepts**: The first step in using an LLM to generate scientific hypotheses and research ideas is to identify the relevant keywords and concepts in the field of study. This can be done by conducting a literature review, analyzing recent conference proceedings, or using other methods to identify trends and topics in the field.
- **Generating prompts based on the combination of keywords and concepts**: Once the relevant keywords and concepts have been identified, the next step is to create a set of prompts based on the combination of these keywords and concepts. 
  - For example, a prompt could be "What are the potential applications of combining X and Y in the field of Z?" or "What are the current limitations of using X in the study of Y and how could they be overcome?", "write a reserach proposal about X and Y in the field of Z", etc.
- **Generating hypotheses and research ideas based on the prompts**: The final step is to use the LLM to generate hypotheses and research ideas based on the prompts. This can be done by feeding the prompts into the LLM and using its output as a starting point for further exploration and refinement.

{% highlight python %} 
input: list of keywords and concepts in field of study

# Step 1: Find keywords and concepts
keywords_and_concepts = identify_keywords_and_concepts(input)

# Step 2: Generate prompts based on combination of keywords and concepts
prompts = generate_prompts(keywords_and_concepts)

# Step 3: Generate hypotheses and research ideas based on prompts
hypotheses_and_ideas = generate_hypotheses_and_ideas(prompts, LLM)

output: list of hypotheses and research ideas
{% endhighlight %}

## Evaluation

Evaluating the ability of large language models to generate scientifically valid hypotheses and research ideas is a crucial step in understanding the potential of these models in the scientific discovery process. There are several ways to evaluate the hypotheses and ideas generated by a large language model:

- **Comparison to existing hypotheses and research ideas**: The hypotheses and ideas generated by the model can be compared to existing ones in the scientific literature to assess their validity and originality. Researchers can use metrics such as the Jaccard similarity coefficient, which measures the similarity between the sets of hypotheses and ideas generated by the model and those from existing literature.
- **Expert evaluation**: Domain experts can be asked to evaluate the hypotheses and ideas generated by the model, and provide feedback on their scientific validity and potential. Interviews with domain experts can also be conducted to gather their thoughts on the usefulness and potential of large language models in the scientific discovery process.
- **Pilot testing**: Some of the hypotheses and research ideas generated by the model can be selected for pilot testing, and their validity and potential can be evaluated by conducting small-scale experiments or simulations.
- **Novelty measurement**: Researchers can use metrics such as Nearest Neighbors or ConceptNet to measure the originality or novelty of the idea generated by the model.
Reasoning and consistency checks: Researchers can check the logic, internal consistency and reasoning in the generated hypotheses and research ideas, and evaluate the model's understanding of the problem and how it reason about it.

## Discussion

The use of Large Language Models (LLMs) for generating scientific hypotheses and research ideas presents several opportunities and challenges. In this section, we will discuss the advantages and limitations of using LLMs in the scientific process.

### Advantages of using LLMs for scientific hypothesis/research ideas generation

There are several advantages to using large language models to propose scientific hypotheses and research ideas, such as:

- **Efficiency**: Large language models can analyze large amounts of data quickly and generate hypotheses and ideas at a faster pace than humans, which could speed up the scientific discovery process.
- **Unbiased and diverse thinking**: One of the main advantages of using LLMs for scientific hypothesis generation is that they can provide unbiased and diverse thinking that may not be limited by human biases or prior 
- **Interdisciplinary reach**: Language models have been trained on a vast variety of text, therefore they have the capability to reach into many domains and interdisciplinary fields which could generate ideas that humans might not have thought of before.
- **Continual learning**: Large language models can be retrained with new data, which would mean they can learn and develop with new research over time, which can lead to even more innovative ideas over time.

### Disadvantages of Using a Large Language Model to Propose Scientific Hypotheses or Research Ideas

There are several disadvantages of using a large language model to propose scientific hypotheses or research ideas, including:

- **Lack of critical thinking**: Finally, it is important to note that LLMs do not possess the critical thinking and evaluation skills of human researchers. Therefore, the output of the models should always be carefully evaluated and validated before being considered for scientific investigation.
- **Limitations in scientific knowledge:** Large language models are only as knowledgeable as the data they were trained on, and their training data may have gaps or be incomplete, leading to limitations in the hypotheses or ideas they can generate.
- **Lack of domain expertise:** Large language models may not have the same level of domain expertise or knowledge as human experts in a specific field, which could limit the quality or validity of the hypotheses or ideas they generate.
- **Bias in the training data:** The training data used to train a large language model can reflect the biases and limitations of the people who created and annotated it. This could result in the model generating hypotheses or ideas that are biased or limited in some way.


## Conclusion


## Related links

- [Large language models will change science](https://xcorr.net/2022/05/30/large-language-models-will-change-science/) by Patrick Mineault May 30, 2022, mainly discuss about understanding the information rather than "creativity"
- [The AI Research Assistant](https://elicit.org)
  - "Elicit uses language models to help you automate research workflows, like parts of literature review. Elicit can find relevant papers without perfect keyword match, summarize takeaways from the paper specific to your question, and extract key information from the papers."
- [How to Build GPT-3 for Science](https://future.com/how-to-build-gpt-3-for-science/) by Josh Nicholson August 18, 2022, mainly discuss about how to build a LLM for science.
- [What ChatGPT and generative AI mean for science](https://www.nature.com/articles/d41586-023-00340-6) by Chris Stokel-Walker & Richard Van Noorden *Nature* Feb 03, 2023 , mainly discuss about the text revision.

## Case study


### Case 1 - generating hypotheses and research ideas by generate title and abstract of a paper


<blockquote>
**the prompt**
Paper Title: "Exploring the Potential of Pre-Trained Language Models for Scientific Hypothesis Generation"
Abstract: With the recent advancements in language models, such as GPT-3, there has been a surge of interest in using them for a variety of natural language processing tasks. In this paper, we examine the potential of these models for generating scientific hypotheses and research ideas. We propose a framework for leveraging the large pre-trained language models to extract relevant information from scientific articles, synthesize new knowledge, and generate hypotheses based on that knowledge. Our results demonstrate that the pre-trained language models can effectively extract scientific knowledge and generate novel and relevant hypotheses in various scientific domains. This study provides new insights into the potential of language models for scientific hypothesis generation and highlights the need for further research in this area.
</blockquote>


> give me some possible research paper titles about spatial genomics + Proteomics + single cell 

- "Integrating Spatial Genomics, Proteomics, and Single-Cell Analysis for a Comprehensive Understanding of Cellular Heterogeneity"
- "Single-Cell Proteomics and Spatial Genomics: Decoding the Complexities of Tissue Microenvironments"
- "Exploring the Intersection of Spatial Genomics, Proteomics, and Single-Cell Analysis in Cancer Research"
- "Spatial Genomics, Proteomics, and Single-Cell Analysis: A Powerful Combination for Understanding Developmental Biology"
- "Uncovering the Dynamics of Cellular Systems through Spatial Genomics, Proteomics, and Single-Cell Analysis"
- "A systems biology approach to cellular heterogeneity: integrating Spatial Genomics, Proteomics, and Single-cell data"
- "From single cell to organism: Spatial Genomics and Proteomics in Development"
- "Exploring the Interplay between Chromatin, Proteins and transcriptional networks by integrating Spatial Genomics, Proteomics and single-cell analysis"

</blockquote>

<blockquote>
write 10 paper titles about reinforce learning and differential privacy

- "Combining Reinforcement Learning and Differential Privacy for Secure Recommender Systems"
- "Preserving Privacy in Multi-Agent Reinforcement Learning with Differential Privacy"
- "Differentially Private Reinforcement Learning for Privacy-Sensitive Decision Making in Healthcare"
- "Differentially Private Reinforcement Learning for Robust Control of Autonomous Systems"
- "Applying Differential Privacy to Deep Reinforcement Learning for Safe Exploration in Robotics"
- "Differentially Private Reinforcement Learning for Privacy-Preserving Human-Robot Interaction"
- "Differentially Private Reinforcement Learning for Secure Online Learning in Cyber-Physical Systems"

</blockquote>

