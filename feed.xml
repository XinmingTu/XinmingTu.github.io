<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://xinmingtu.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://xinmingtu.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-01-20T05:07:26+00:00</updated><id>https://xinmingtu.github.io/feed.xml</id><title type="html">Xinming Tu</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">AI for General Science - Large language models for scientific hypothesis/research ideas generation</title><link href="https://xinmingtu.github.io/blog/2023/LLM_science/" rel="alternate" type="text/html" title="AI for General Science - Large language models for scientific hypothesis/research ideas generation"/><published>2023-02-07T00:00:00+00:00</published><updated>2023-02-07T00:00:00+00:00</updated><id>https://xinmingtu.github.io/blog/2023/LLM_science</id><content type="html" xml:base="https://xinmingtu.github.io/blog/2023/LLM_science/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Artificial intelligence and machine learning have been making significant advancements in various fields, including science. However, the use of Large Language Models(LLMs) in the scientific community has been limited to fine-tuning models for specific domains, such as medical question-answering, or revision of existing text. This is due to concerns about the accuracy and reliability of the generated content, as LLMs are known to sometimes generate information that is not supported by existing data or publication.</p> <p>However, <strong>if we approach the use of LLMs differently, and view them not as a source of truth, but rather as a tool for generating new and creative ideas</strong>, they have the potential to be extremely valuable in the scientific community. LLMs are not limited by the implicit biases or boundaries of the human mind, and when combined with automated algorithms, they have the potential to generate new and innovative research ideas that may have been missed by scientists working alone.</p> <p>The process of generating scientific hypotheses and research ideas is a complex and time-consuming task that requires creativity, critical thinking, and a thorough understanding of the field. With the use of LLMs, scientists can access a vast knowledge base and generate new ideas at a much faster rate, potentially leading to new breakthroughs and discoveries.</p> <p>In this blog, we will explore the potential of using LLMs as a tool for generating scientific hypotheses and research ideas, and the advantages and limitations of this approach.</p> <h2 id="related-posts">Related posts</h2> <ul> <li><a href="https://xcorr.net/2022/05/30/large-language-models-will-change-science/">Large language models will change science</a> by Patrick Mineault May 30, 2022, mainly discuss about “understanding” the information rather than “creativity”</li> <li><a href="https://elicit.org">The AI Research Assistant</a> <ul> <li>“Elicit uses language models to help you automate research workflows, like parts of literature review. Elicit can find relevant papers without perfect keyword match, summarize takeaways from the paper specific to your question, and extract key information from the papers.”</li> </ul> </li> <li><a href="https://future.com/how-to-build-gpt-3-for-science/">How to Build GPT-3 for Science</a> by Josh Nicholson August 18, 2022, discuss about how to build a LLM for science.</li> <li><a href="https://www.nature.com/articles/d41586-023-00340-6">What ChatGPT and generative AI mean for science</a> by Chris Stokel-Walker &amp; Richard Van Noorden, <em>Nature</em> Feb 03, 2023 , discuss about the text revision.</li> </ul> <h2 id="method">Method</h2> <p>In this section, I will give a initial idea about how to use LLMs to generate scientific hypotheses and research ideas.</p> <p>The process can be broken down into three main steps:</p> <ul> <li><strong>Finding keywords and concepts</strong>: The first step in using an LLM to generate scientific hypotheses and research ideas is to identify the relevant keywords and concepts in the field of study. This can be done by conducting a literature review by LLM, analyzing recent conference proceedings, or using other methods to identify trends and topics in the field.</li> <li><strong>Generating prompts based on the combination of keywords and concepts</strong>: Once the relevant keywords and concepts have been identified, the next step is to create a set of prompts based on the combination of these keywords and concepts. <ul> <li>For example, a prompt could be “What are the potential applications of combining X and Y in the field of Z?” or “What are the current limitations of using X in the study of Y and how could they be overcome?”, “write a reserach proposal about X and Y in the field of Z”, etc.</li> </ul> </li> <li><strong>Generating hypotheses and research ideas based on the prompts</strong>: The final step is to use the LLM to generate hypotheses and research ideas based on the prompts. This can be done by feeding the prompts into the LLM and using its output as a starting point for further exploration and refinement.</li> </ul> <figure class="highlight"><pre><code class="language-python" data-lang="python"> 
<span class="nb">input</span><span class="p">:</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">keywords</span> <span class="ow">and</span> <span class="n">concepts</span> <span class="ow">in</span> <span class="n">field</span> <span class="n">of</span> <span class="n">study</span>

<span class="c1"># Step 1: Find keywords and concepts
</span><span class="n">keywords_and_concepts</span> <span class="o">=</span> <span class="nf">identify_keywords_and_concepts</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="c1"># Step 2: Generate prompts based on combination of keywords and concepts
</span><span class="n">prompts</span> <span class="o">=</span> <span class="nf">generate_prompts</span><span class="p">(</span><span class="n">keywords_and_concepts</span><span class="p">)</span>

<span class="c1"># Step 3: Generate hypotheses and research ideas based on prompts
</span><span class="n">hypotheses_and_ideas</span> <span class="o">=</span> <span class="nf">generate_hypotheses_and_ideas</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">LLM</span><span class="p">)</span>

<span class="n">output</span><span class="p">:</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">hypotheses</span> <span class="ow">and</span> <span class="n">research</span> <span class="n">ideas</span></code></pre></figure> <h2 id="advantages-and-limitations">Advantages and limitations</h2> <p>The use of Large Language Models (LLMs) for generating scientific hypotheses and research ideas presents several opportunities and challenges. In this section, we will discuss the advantages and limitations of using LLMs in the scientific process.</p> <h3 id="advantages">Advantages</h3> <p>There are several advantages to using large language models to propose scientific hypotheses and research ideas, such as:</p> <ul> <li><strong>Efficiency</strong>: Large language models can analyze large amounts of data quickly and generate hypotheses and ideas at a faster pace than humans, which could speed up the scientific discovery process.</li> <li><strong>Unbiased and diverse thinking</strong>: One of the main advantages of using LLMs for scientific hypothesis generation is that they can provide unbiased and diverse thinking that may not be limited by human biases or prior</li> <li><strong>Interdisciplinary reach</strong>: Language models have been trained on a vast variety of text, therefore they have the capability to reach into many domains and interdisciplinary fields which could generate ideas that humans might not have thought of before.</li> <li><strong>Continual learning</strong>: Large language models can be retrained with new data, which would mean they can learn and develop with new research over time, which can lead to even more innovative ideas over time.</li> </ul> <h3 id="limitations">Limitations</h3> <p>There are several disadvantages of using a large language model to propose scientific hypotheses or research ideas, including:</p> <ul> <li><strong>Lack of critical thinking</strong>: Finally, it is important to note that LLMs do not possess the critical thinking and evaluation skills of human researchers. Therefore, the output of the models should always be carefully evaluated and validated before being considered for scientific investigation.</li> <li><strong>Limitations in scientific knowledge:</strong> Large language models are only as knowledgeable as the data they were trained on, and their training data may have gaps or be incomplete, leading to limitations in the hypotheses or ideas they can generate.</li> <li><strong>Lack of domain expertise:</strong> Large language models may not have the same level of domain expertise or knowledge as human experts in a specific field, which could limit the quality or validity of the hypotheses or ideas they generate.</li> <li><strong>Bias in the training data:</strong> The training data used to train a large language model can reflect the biases and limitations of the people who created and annotated it. This could result in the model generating hypotheses or ideas that are biased or limited in some way.</li> </ul> <h2 id="case-studies">Case studies</h2> <p>Now, we will use a few cases as a demonstration of how to use LLMs to generate scientific hypotheses and research ideas.</p> <h3 id="scenario-1-generation-of-a-research-paper-title-and-abstract-for-this-blog-post">Scenario 1: Generation of a Research Paper Title and Abstract for this blog post</h3> <p>In fact, we can utilize ChatGPT to generate content relevant to this blog post</p> <blockquote> <p><strong>Prompt</strong>: <code class="language-plaintext highlighter-rouge">write a paper title about Leveraging Large Language Models to Propose Scientific Hypotheses and Research Ideas, and the abstract</code></p> </blockquote> <p><strong>Title</strong>: “Exploring the Potential of Pre-Trained Language Models for Scientific Hypothesis Generation”</p> <p><strong>Abstract</strong>: With the recent advancements in language models, such as GPT-3, there has been a surge of interest in using them for a variety of natural language processing tasks. In this paper, we examine the potential of these models for generating scientific hypotheses and research ideas. We propose a framework for leveraging the large pre-trained language models to extract relevant information from scientific articles, synthesize new knowledge, and generate hypotheses based on that knowledge. Our results demonstrate that the pre-trained language models can effectively extract scientific knowledge and generate novel and relevant hypotheses in various scientific domains. This study provides new insights into the potential of language models for scientific hypothesis generation and highlights the need for further research in this area.</p> <blockquote> <p><strong>Comments</strong>: <em>The generated title and abstract effectively capture the essence of the blog post, providing a clear and concise overview of its main content.</em></p> </blockquote> <h3 id="scenario-2-generation-of-a-research-proposal-from-a-generated-paper-title-using-keywords">Scenario 2: Generation of a Research Proposal from a Generated Paper Title Using Keywords</h3> <p>Moreover, a Large Language Model can be leveraged to generate a paper title by inputting a list of relevant keywords.</p> <blockquote> <p><strong>Prompt</strong>: <code class="language-plaintext highlighter-rouge">give me some possible research paper titles about spatial genomics + Proteomics + single cell</code></p> </blockquote> <ul> <li>“Integrating Spatial Genomics, Proteomics, and Single-Cell Analysis for a Comprehensive Understanding of Cellular Heterogeneity”</li> <li>“Single-Cell Proteomics and Spatial Genomics: Decoding the Complexities of Tissue Microenvironments”</li> <li>“Exploring the Intersection of Spatial Genomics, Proteomics, and Single-Cell Analysis in Cancer Research”</li> <li>“Spatial Genomics, Proteomics, and Single-Cell Analysis: A Powerful Combination for Understanding Developmental Biology”</li> <li>“Uncovering the Dynamics of Cellular Systems through Spatial Genomics, Proteomics, and Single-Cell Analysis”</li> <li>“Exploring the Interplay between Chromatin, Proteins and transcriptional networks by integrating Spatial Genomics, Proteomics and single-cell analysis”</li> </ul> <blockquote> <p><strong>Comments:</strong> <em>The titles generated in the study are very relevant to the provided keywords and concepts, making it difficult to distinguish between real and generated titles. Upon conducting a Google search, there were real papers related to some of the generated titles, but no exact matches were found.</em></p> </blockquote> <p>Now, we can use the generated title as the starting point for the development of a comprehensive research proposal.</p> <blockquote> <p><strong>Prompt</strong>: <code class="language-plaintext highlighter-rouge">write a research proposal about "Single-Cell Proteomics and Spatial Genomics: Decoding the Complexities of Tissue Microenvironments"</code></p> </blockquote> <p><strong>Title:</strong> Decoding the Complexities of Tissue Microenvironments through Single-Cell Proteomics and Spatial Genomics</p> <p><strong>Introduction:</strong> The study of complex biological systems, such as tissues, has been traditionally limited by the resolution of the technologies used to analyze them. While progress has been made in the fields of single-cell transcriptomics and genome sequencing, the protein content of cells and its spatial organization within tissues remains largely unknown. Single-cell proteomics and spatial genomics have emerged as powerful tools to address these limitations and provide a more complete understanding of tissue microenvironments.</p> <p><strong>Objectives:</strong> The goal of this proposal is to explore the use of single-cell proteomics and spatial genomics to decode the complexities of tissue microenvironments. Specifically, this study aims to:</p> <p>Characterize the protein content of individual cells within a tissue. Determine the spatial organization of proteins within tissues. Identify novel cell types and functional interactions between cells within a tissue.</p> <p><strong>Methods:</strong> The study will involve the collection of tissue samples from a well-characterized model organism and the analysis of these samples using single-cell proteomics and spatial genomics techniques. To achieve the first objective, cells will be isolated and their protein content will be characterized through mass spectrometry. To achieve the second objective, the spatial organization of proteins will be determined through the use of tissue clearing and imaging methods such as CLARITY and Light-sheet Fluorescence Microscopy. To achieve the third objective, the data obtained from the first two objectives will be integrated with existing transcriptomic and genomic data to identify novel cell types and functional interactions within the tissue.</p> <p><strong>Expected Outcomes:</strong> The study is expected to provide a comprehensive characterization of the protein content and spatial organization of cells within a tissue. This information will be valuable for understanding the functional interactions between cells within a tissue and for uncovering new biological insights into the regulation of tissue function.</p> <p><strong>Conclusion:</strong> In conclusion, this study will provide a cutting-edge investigation into the complexities of tissue microenvironments through the use of single-cell proteomics and spatial genomics. The findings of this study have the potential to significantly advance our understanding of tissues and will provide a foundation for future studies aimed at improving our understanding of the biological mechanisms underlying tissue function.</p> <blockquote> <p><strong>Comments:</strong> <em>The generated research proposal is well-rounded and includes all essential components of a research proposal. The introduction and objectives align well with the generated title, and the methods and expected outcomes seem reasonable. Overall, it is a solid piece of work.</em></p> </blockquote> <hr/> <h3 id="scenario-3---direct-generation-of-a-research-proposal-from-keywords">Scenario 3 - Direct Generation of a Research Proposal from Keywords</h3> <p>In Scenario 3, the aim is to generate a complete research proposal directly from a set of keywords. This approach leverages the language generation capabilities of the LLM to transform the keywords into a full-fledged research proposal.</p> <blockquote> <p><strong>Prompt</strong>: <code class="language-plaintext highlighter-rouge">write a research proposal about Reinforcement Learning + Differential Privacy</code></p> </blockquote> <p><strong>Title</strong>: “Enhancing Differential Privacy in Reinforcement Learning Algorithms for Personalized Decision Making”</p> <p><strong>Introduction:</strong> Reinforcement learning (RL) algorithms are increasingly being used for personalized decision making in various domains, including healthcare, finance, and transportation. However, the use of RL algorithms often raises privacy concerns, as they require access to sensitive personal data to make accurate predictions. To address this issue, differential privacy (DP) has been proposed as a means to provide privacy-preserving solutions for data analysis. In this study, we propose to enhance the privacy guarantees of RL algorithms by integrating them with DP techniques.</p> <p><strong>Objectives:</strong> The main objective of this research is to develop a new approach for personalized decision making that combines the strengths of RL algorithms and DP techniques. The proposed approach will provide strong privacy guarantees while maintaining the accuracy of RL algorithms.</p> <p><strong>Methods</strong>: The proposed research will involve the following steps:</p> <p>A thorough review of existing RL algorithms and DP techniques for privacy-preserving data analysis. Development of a new RL algorithm that integrates DP techniques to enhance privacy guarantees. Empirical evaluation of the proposed approach using simulated and real-world data sets.</p> <p><strong>Evaluation Metrics</strong>: The proposed approach will be evaluated using the following metrics:</p> <p>Privacy: The privacy guarantees provided by the proposed approach will be evaluated using standard metrics, such as entropy and mutual information. Accuracy: The accuracy of the proposed approach will be evaluated by comparing its predictions to those made by traditional RL algorithms. Efficiency: The computational efficiency of the proposed approach will be evaluated in terms of run-time and memory usage.</p> <p><strong>Expected Outcomes:</strong> The expected outcomes of this research are:</p> <p>A new RL algorithm that integrates DP techniques to enhance privacy guarantees. Improved privacy guarantees for RL algorithms for personalized decision making. Increased understanding of the trade-off between privacy and accuracy in RL algorithms. Conclusion: This study will contribute to the development of privacy-preserving solutions for personalized decision making based on RL algorithms. The proposed approach has the potential to impact various domains, including healthcare, finance, and transportation, where privacy and accuracy are both important concerns. The results of this research will inform future work in this area and provide new insights into the challenges and opportunities of combining RL algorithms and DP techniques.</p> <blockquote> <p><strong>Comments:</strong> <em>The generated research proposal showcases the remarkable ability of the LLM model in connecting seemingly unrelated ideas and forming new connections. The identification of Personalized Decision Making as a connection between Reinforcement Learning and Differential Privacy is truly remarkable and highlights the potential of LLMs in scientific research. The proposal is organized and comprehensive, with all of the key elements of a research proposal in place, including the introduction, objectives, methods, and expected outcomes. Overall, this proposal is a testament to the innovative capabilities of LLMs in generating new and insightful research ideas.</em></p> </blockquote> <hr/> <h2 id="discussion">Discussion</h2> <p>In this blog, we took a look at the possibility of using Large Language Models to generate scientific hypotheses and research ideas through a few case studies. While the cases provide a glimpse of what LLMs are capable of, there is much room for further investigation and refinement of the technology.</p> <p>The development of an automated research idea and hypothesis generation system is a promising future prospect. This system would be capable of incorporating the collective knowledge of the scientific community, analyzing vast amounts of information, identifying trends and patterns, and synthesizing novel research directions based on these findings. With this technology, scientists would have access to an unprecedented source of inspiration and guidance, leading to more efficient and effective scientific discovery and progress.</p> <p>In the current landscape of scientific research, staying up-to-date with the latest developments and ideas can be challenging. The use of LLMs can help scientists overcome these difficulties by generating new, unique ideas that are based on the latest research and trends, streamlining the research process and breaking the limitations of researchers’ implicit knowledge.</p> <p>In conclusion, the use of LLMs for scientific hypothesis and research idea generation holds the potential to revolutionize the way scientific breakthroughs are achieved. By providing an unbiased and creative approach to research idea generation, LLMs have the potential to significantly increase the speed and efficiency of scientific discovery. We hope that this blog post will inspire more researchers to explore the possibilities of incorporating LLMs into their own work.</p> <h2 id="acknowledgements">Acknowledgements</h2> <p>I would like to extend our gratitude to Jiahui Peng, Zixuan Liu, and Hanwen Xu for their valuable feedback and discussion on this idea.</p> <p>I would also like to give a special thank you to ChatGPT for its contributions to this post. With its language generation capabilities, it was instrumental in composing the majority of the paragraphs based on my given outline.</p>]]></content><author><name>Xinming Tu</name></author><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">A framework to understand regulatory genomics(To be finished)</title><link href="https://xinmingtu.github.io/blog/2022/seq2func/" rel="alternate" type="text/html" title="A framework to understand regulatory genomics(To be finished)"/><published>2022-07-01T00:00:00+00:00</published><updated>2022-07-01T00:00:00+00:00</updated><id>https://xinmingtu.github.io/blog/2022/seq2func</id><content type="html" xml:base="https://xinmingtu.github.io/blog/2022/seq2func/"><![CDATA[<h2 id="background">Background</h2> <p>One of the central questions in genetics is understanding the relationship between genotype and phenotype. Genotype refers to an individual’s genome, or their complete set of DNA sequences, while phenotype refers to observable traits such as physical characteristics and disease states. A deeper understanding of the relationship between genotype and phenotype requires an examination of the intermediate processes that link the two. One of the most important of these processes is gene regulation, which is a multi-layered, context-dependent process. It involves interactions between various elements, including regulatory elements, the abundance of transcription factors, chromatin states, and various epigenetic modifications. Together, these intermediate processes and variables can be referred to as epigenotype/epigenomics, which plays a crucial role in determining an individual’s observable traits</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/seq2func/Geno2Pheno.pdf-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/seq2func/Geno2Pheno.pdf-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/seq2func/Geno2Pheno.pdf-1400.webp"/> <img src="/assets/img/seq2func/Geno2Pheno.pdf" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Take previous research topics as examples, Genome-wide association studies (GWAS) are a powerful tool for understanding the relationship between genotype and phenotype. These studies typically focus on the association between single-nucleotide polymorphisms (SNPs) and various human disease states. Another area of research that examines this relationship is expression quantitative trait loci (eQTL) studies, which investigate the association between genetic variants and epigenotype, specifically gene expression. In recent years, a new type of eQTL called chromatin accessibility quantitative trait loci (caQTL) has emerged, which examines the relationship between genetic variants and chromatin accessibility. These statistical genetics approaches use regression models based on predefined features, such as different alleles, to establish associations. However, this approach has a limitation that it can only introduce mutations that are present in the training data, and the input features of the model are determined by the training data.</p> <p><strong>What’s regulatory genomics?</strong> In my view, Regulatory genomics is a field of study that aims to understand the underlying mechanisms of gene regulation at a higher resolution. This is achieved by using computational and experimental approaches to predict the epigenotypes from DNA sequences, which allows for a more flexible exploration of the genotype-phenotype relationship than traditional statistical genetics methods. Regulatory genomics often uses bioinformatics tools and techniques such as genome-wide ChIP-seq, RNA-seq, and ATAC-seq, to identify and analyze different types of regulatory elements, including transcription factors, enhancers, and promoter regions, with the goal of understanding how these elements interact to regulate gene expression and ultimately affect the phenotype.</p> <table> <thead> <tr> <th><strong>Study</strong></th> <th><strong>Genotypes</strong></th> <th><strong>Epigenotypes</strong></th> <th><strong>Phenotypes</strong></th> </tr> </thead> <tbody> <tr> <td>GWAS</td> <td>Variants</td> <td>-</td> <td>traits(disease)</td> </tr> <tr> <td>eQTL</td> <td>Variants</td> <td>Gene expression</td> <td>-</td> </tr> <tr> <td>caQTL</td> <td>Variants</td> <td>Chromatin accessibility</td> <td>-</td> </tr> <tr> <td>Regulatory genomics</td> <td>DNA sequences</td> <td>Genomics tracks</td> <td>-</td> </tr> </tbody> </table> <p>In this blog, I will provide an in-depth overview of the field of regulatory genomics. I will start by introducing a general framework that outlines the key concepts and principles of the field. Afterward, I will delve into specific examples by discussing two types of data that are commonly used in regulatory genomics: genome sequences and synthetic sequences. Additionally, I will highlight some of the recent research papers that have contributed to the progress and advancements in the field. To conclude, I will explore the different ways in which the models developed in regulatory genomics can be applied to gain new insights into the mechanisms of gene regulation and the relationship between genotype and phenotype.</p> <h2 id="the-general-framework">The general framework</h2> <p>The overarching objective of regulatory genomics is to accurately predict functional outcomes and activity levels derived from DNA sequences. This process involves the utilization of sophisticated computational models that accept DNA sequences, composed of nucleotides adenine (A), cytosine (C), thymine (T), and guanine (G), as input variables \(X\). Subsequently, these models generate predictions for the activity of a diverse array of genomic features \(Y\), including but not limited to, gene expression, chromatin accessibility, and three-dimensional genome organization. The output generated for these genomic features can be represented as either a scalar value or a multidimensional vector, contingent upon the specific genomic track being analyzed.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/seq2func/Framework.pdf-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/seq2func/Framework.pdf-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/seq2func/Framework.pdf-1400.webp"/> <img src="/assets/img/seq2func/Framework.pdf" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="two-kinds-of-data">Two kinds of data</h2> <p>A crucial aspect of developing models in regulatory genomics is selecting the appropriate data source. Two commonly used data sources in this field are genome sequences and synthetic sequences. Genome sequences are obtained through sequencing technology and provide a snapshot of the genomic landscape in a natural context. They are useful for studying the effects of genetic variations on gene regulation. Synthetic sequences, on the other hand, are generated using synthetic biology techniques and are used to study the effects of genetic variations in a specific region in a controlled environment, typically in a specific cell line. These data sources provide a unique opportunity to study the effects of genetic modifications on gene regulation.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/seq2func/Two_data.pdf-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/seq2func/Two_data.pdf-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/seq2func/Two_data.pdf-1400.webp"/> <img src="/assets/img/seq2func/Two_data.pdf" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Both types of data sources have their own advantages and limitations, which will be discussed in further detail in the later sections of the blog post</p> <h3 id="the-genome-sequences">The genome sequences</h3> <p>The human genome contains more than six billion base-pairs, which makes it an easily accessible data source for inputting into models. Additionally, various experimental technologies can be utilized to obtain different types of measurements from cells in various states and functions. These technologies include high-throughput sequencing methods such as RNA-seq to measure gene expression, ChIP-seq to measure protein-DNA binding, and ATAC-seq to measure chromatin accessibility, Hi-C to measure 3D genome structure, and more.</p> <p>Models in regulatory genomics take DNA sequences as input and predict the activity of different genomics tracks. These models are trained using large amounts of data obtained through these sequencing technologies and can accurately predict the activity of different genomic tracks in different cell types.</p> <h4 id="sequence-as-input">Sequence as input</h4> <p>Various works focus on predicting specific genomic tracks, such as:</p> <ul> <li>Predict <strong>protein binding</strong> from sequences: DeepBind<d-cite key="alipanahi2015predicting"></d-cite>, DeepSEA<d-cite key="zhou2015predicting"></d-cite>, BPnet<d-cite key="avsec2021base"></d-cite></li> <li>Predict <strong>gene expression</strong> from sequences: Basenji<d-cite key="kelley2018sequential"></d-cite>, ExPecto<d-cite key="zhou2018deep"></d-cite>, Enformer<d-cite key="avsec2021effective"></d-cite></li> <li>Predict <strong>chromatin accessibility</strong> from sequences: Basset<d-cite key="kelley2016basset"></d-cite>, DanQ<d-cite key="quang2016danq"></d-cite> , AI-TAC<d-cite key="maslova2020deep"></d-cite>, AMBER<d-cite key="zhang2021automated"></d-cite></li> <li>Predict <strong>3D structure of the genome</strong> from sequences:Akita<d-cite key="fudenberg2020predicting"></d-cite>, DeepC<d-cite key="schwessinger2020deepc"></d-cite>, Orca<d-cite key="zhou2022sequence"></d-cite></li> </ul> <h4 id="sequence-and-other-modalities-as-input">Sequence and other modalities as input</h4> <p>In addition to using DNA sequences as the sole input, other genomics tracks can also be incorporated as inputs. For example:</p> <ul> <li>Predict <strong>protein binding</strong> from DNA sequences and <strong>Chromatin accessibility</strong>: Leopard<d-cite key="li2021fast"></d-cite>, maxATAC<d-cite key="cazares2022maxatac"></d-cite></li> <li>Predict <strong>gene expression</strong> from sequences and <strong>3D genome structure</strong>: GraphReg<d-cite key="karbalayghareh2022chromatin"></d-cite></li> <li>Predict <strong>3D genome structure</strong> from sequences and <strong>Chromatin accessibility/Protein binding</strong>: C.Origami<d-cite key="tan2022cell"></d-cite></li> </ul> <p>The main motivations behind incorporating other modalities as inputs are: (1)The ability to predict cell-type specific activity directly. (2)The ability to study multi-layer relationships between different genomics tracks.</p> <p>Previous methods that rely solely on DNA sequences as input can only provide a general understanding of gene regulation, as the input for different cells is the same (the same genome). To account for cell-type specific activity, these methods often use a multi-task setting. On the other hand, incorporating other modalities as input, such as chromatin accessibility or protein-DNA binding, allows for direct prediction of cell-type specific activity. For example, if we know that a specific DNA sequence contains a motif and is accessible to a certain protein, we can generalize this understanding to other cell types<d-cite key="li2021fast"></d-cite>. Additionally, incorporating other modalities as input allows for the study of multi-layer relationships between different genomics tracks, providing a more comprehensive understanding of gene regulation<d-cite key="karbalayghareh2022chromatin"></d-cite>.</p> <p>Figure summary:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/seq2func/Genome_examples.pdf-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/seq2func/Genome_examples.pdf-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/seq2func/Genome_examples.pdf-1400.webp"/> <img src="/assets/img/seq2func/Genome_examples.pdf" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h4 id="pros-and-cons-of-using-genome-sequences">Pros and Cons of using genome sequences</h4> <p>Using genome sequences as a data source in regulatory genomics allows for the prediction of the activity of different genomics tracks across long sequences, even entire chromosomes<d-cite key="zhou2022sequence"></d-cite>. This allows for the study of complex mechanisms of the genome, including various types of regulatory processes such as promoters, enhancers, repressors, long-range loops, and changes in compartments. Additionally, by using data from different cell types, it is possible to predict cell-type-specific genomics tracks.</p> <p>However, there are also some disadvantages to using genome sequences as a data source. One of the main limitations is the limited sample size. For example, when predicting gene expression, the sample size is limited to the number of genes. Similarly, when predicting chromatin accessibility, the sample size is limited to the number of open chromatin regions. Another limitation is that the genome is in a state of constant evolution, which limits the diversity of sequences.</p> <ul> <li>Pros of using genome sequences as a data source in regulatory genomics: <ul> <li><strong>Long sequences</strong>: Allows for the prediction of activity across long sequences even entire chromosomes</li> <li><strong>Complex mechanisms</strong>: Enables the study of complex mechanisms of the genome, including various types of regulatory processes.</li> <li><strong>Diverse cell state</strong>: Provides the ability to predict cell-type-specific genomics tracks</li> </ul> </li> <li>Cons of using genome sequences as a data source in regulatory genomics: <ul> <li><strong>Limited sample size</strong>: The number of samples is restricted by the number of genes or open chromatin regions.</li> <li><strong>Limits the diversity of sequences</strong> The genome is in a state of constant evolution, which limits the diversity of sequences</li> </ul> </li> </ul> <h3 id="the-synthesis-sequences">The synthesis sequences</h3> <p>The use of synthetic sequences in regulatory genomics allows for a more versatile approach to investigating the functions of specific elements in the genome. This is achieved by introducing synthesized sequences into different positions in the genome, which allows for the study of the mechanisms of various regulatory regions such as promoters, 3’UTRs, 5’UTRs, and enhancers. There have been numerous studies conducted utilizing this approach, utilizing various techniques such as random sequence generation and site-directed mutagenesis to investigate these mechanisms.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/seq2func/randome_sequence.pdf-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/seq2func/randome_sequence.pdf-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/seq2func/randome_sequence.pdf-1400.webp"/> <img src="/assets/img/seq2func/randome_sequence.pdf" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>For example, We can use synthesize sequences as <strong>Promoter</strong> to study the mechanism of the promoter. We can also use random sequences such as 3’UTR or 5’UTR<d-cite key="sample2019human, cuperus2017deep"></d-cite> to study the mechanism of the 5’UTR or 3’UTR. Furthermore, we can use random sequences as enhancers and <strong>Promoter</strong><d-cite key="sahu2022sequence"></d-cite></p> <p>While there are advantages to using synthesized sequences, such as the large sample size and the ability to synthesize any sequence, there are also limitations. For example, experiments using synthesized sequences are typically limited to simple systems such as yeast/cell-line and the sequences used are usually short (typically no longer than 300 base pairs). This results in a more local and simple understanding of the mechanisms at play.</p> <h4 id="pros-and-cons-of-using-random-sequences">Pros and Cons of using random sequences</h4> <p>However, We only can study <strong>the simple system</strong>(such as yeast) in this way, and the sequence will be <strong>short</strong>(usually the length is not longer than 300). As a result, the mechanism will also be very <strong>local</strong> and <strong>simple</strong>.</p> <ul> <li>Pros: <ul> <li><strong>Large sample size</strong>: The ability to generate a large number of random sequences allows for a larger sample size in studies.</li> <li><strong>Flexible sequences</strong>: There are no constraints on the sequences that can be synthesized, allowing for a wide range of possibilities.</li> <li><strong>Experimental validation</strong>: The ability to synthesize specific sequences make it easy for direct experimental validation of model predictions.</li> </ul> </li> <li>Cons: <ul> <li><strong>Simple system</strong>: Synthetic biology techniques are typically only feasible for studying simple organisms like yeast or Cell-line.</li> <li><strong>Short sequences</strong>: The length of synthesized sequences is typically limited to around 300 base pairs or less.</li> <li><strong>Simple mechanism</strong>: Studies using synthetic biology techniques are limited to understanding local, simple mechanisms rather than complex, systemic interactions.</li> </ul> </li> </ul> <h2 id="from-model-to-new-biology">From model to new biology</h2> <p>Now, we have the data and the model. The final goal is to find new biology insights. So we need to dig into the model and find the new biology. There are two ways to do this: <strong>Deciphering</strong> and <strong>Engineering</strong>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/seq2func/new_biology.pdf-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/seq2func/new_biology.pdf-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/seq2func/new_biology.pdf-1400.webp"/> <img src="/assets/img/seq2func/new_biology.pdf" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3 id="decipher-the-regulatory-process-from-the-model">Decipher the regulatory process from the model</h3> <p>The first kind of application is to decipher the regulatory process from the model.</p> <p>After the training, the model already knows the regulatory process. So we can use the explainable AI method(Such as DeepLift<d-cite key="shrikumar2017learning"></d-cite>, SHAPLY<d-cite key="lundberg2017unified"></d-cite>) to decipher the regulatory process<d-cite key="novakovsky2022obtaining"></d-cite>.</p> <p>We can learn the regulatory elements from the model(TF-Modisco<d-cite key="shrikumar2018technical"></d-cite>) and also get the relationship between the regulatory elements.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/seq2func/Decipher_model.pdf-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/seq2func/Decipher_model.pdf-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/seq2func/Decipher_model.pdf-1400.webp"/> <img src="/assets/img/seq2func/Decipher_model.pdf" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3 id="simulator-to-optimize-and-do-experiments-in-virtual">Simulator to optimize and do experiments in virtual</h3> <p>The second kind of application is using the model to simulate the process virtually and we can also use the simulator to optimize the sequence and do engineering experiments.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/seq2func/model_simulator.pdf-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/seq2func/model_simulator.pdf-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/seq2func/model_simulator.pdf-1400.webp"/> <img src="/assets/img/seq2func/model_simulator.pdf" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>We have a trusty simulator(Simulator) and we can use the simulator to do experiments virtually and introduce mutations/perturbation to study the effect of variants which can even extend to large structure variants (such as deletion, insertion, and duplication). Also, we can use the simulator to do some evolutionary studies. We can mimic the evolution of the regulatory process.</p> <h2 id="summary">Summary</h2> <p>So in this post, we have learned the following: There are two kinds of data: The genome sequences/the synthesis sequences and two kinds of ways to get new biology: Deciphering the regulatory process from the model, Simulator to optimize and do experiments in virtual</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/seq2func/Summary.pdf-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/seq2func/Summary.pdf-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/seq2func/Summary.pdf-1400.webp"/> <img src="/assets/img/seq2func/Summary.pdf" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="case-study">Case study</h2> <p>In this section, we list some papers as case studies to better understand the framework.</p> <h2 id="related-reviews">Related reviews</h2> <p>There are also some really great related reviews: If you want to know more about regulatory genomics, you can read the following reviews:</p> <ul> <li>Decoding disease: from genomes to networks to phenotypes<d-cite key="wong2021decoding"></d-cite></li> <li>Obtaining genetics insights from deep learning via explainable artificial intelligence<d-cite key="novakovsky2022obtaining"></d-cite></li> </ul>]]></content><author><name>Xinming Tu</name></author><summary type="html"><![CDATA[Background]]></summary></entry><entry><title type="html">Collection of some resources related to the PhD journey.</title><link href="https://xinmingtu.github.io/blog/2022/Academic-resource/" rel="alternate" type="text/html" title="Collection of some resources related to the PhD journey."/><published>2022-06-30T00:00:00+00:00</published><updated>2022-06-30T00:00:00+00:00</updated><id>https://xinmingtu.github.io/blog/2022/Academic-resource</id><content type="html" xml:base="https://xinmingtu.github.io/blog/2022/Academic-resource/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Last quarter, I took the Tao of the Ph.D. seminar at the University of Washington. I was in California and couldn’t get involved as much but I still learned a lot from the recommended resources covering many important topics for Ph.D. students. In addition, I also learned a lot from the internet(Video, Blog, Article, Podcast), so I want to make a collection of them.<d-footnote> Some of them are written in Chinese, which means the original posts are in Chinese </d-footnote></p> <p>Reading stories of people who have gone through the same journey is a virtual way to gain experience - It’s like <strong>reading a cheat sheet while playing games</strong>!</p> <p>Before applying for the Ph.D., I recommend some articles to read! <strong>PhD is not necessary for all people</strong>.</p> <ul> <li><a href="https://medium.com/great-research/do-you-need-a-ph-d-f78d2fb0f286">Do you need a PhD?</a> by Nick Feamster</li> <li><a href="https://freedom-to-tinker.com/2010/09/27/advice-new-graduate-students/">Advice for new graduate students</a> by Jennifer Rexford</li> </ul> <h2 id="research-topic">Research Topic</h2> <p>Research is one of the most important things in the life of a PhD student.</p> <ul> <li><a href="http://www.cs.virginia.edu/~robins/YouAndYourResearch.pdf">You and your research</a> by Richard Hamming. It’s a little bit hard for early career researchers to follow all instructions but we should always remind ourselves of these points. <ul> <li>“Once you get your courage up and believe that you can do important problems, then you can. “</li> <li>“If you do not work on an important problem, it’s unlikely you’ll do important work. It’s perfectly obvious.”</li> <li>“If you really want to be a first-class scientist you need to know yourself, your weaknesses, your strengths, and your bad faults”</li> </ul> </li> <li><a href="https://greatresearch.org/2013/09/20/research-patterns/">Research patterns</a> by Nick Feamster. He provided some patterns for finding a problem and solving it. Check more detail in the post! <ul> <li>“Revisit old problems where assumptions may have changed.”</li> <li>“Hop on a trend; look “upstream” for the trends.”</li> <li>“Specialize the general. Generalize the specific “</li> <li>“Think in speech or pictures”</li> </ul> </li> <li><a href="https://journals.biologists.com/jcs/article/121/11/1771/30038/The-importance-of-stupidity-in-scientific-research">Importance of stupidity</a> by Martin Schwartz <ul> <li>“Science involves confronting our ‘absolute stupidity. That kind of stupidity is an existential fact, inherent in our efforts to push our way into the unknown.”</li> <li>“The more comfortable we become with being stupid, the deeper we will wade into the unknown and the more likely we are to make big discoveries.”</li> </ul> </li> <li><a href="https://www.weizmann.ac.il/mcb/UriAlon/sites/mcb.UriAlon/files/uploads/nurturing/howtochoosegoodproblem.pdf">How to choose a good scientific problem</a> by Uri Alon. <ul> <li>We should keep <em>The Feasibility-Interest Diagram for Choosing a Project</em> and <em>The Schema of Research</em> in mind</li> </ul> </li> <li><a href="https://medium.com/@marcotcr/coming-up-with-research-ideas-3032682e5852">Coming up with research ideas</a> by Marco Tulio Ribeiro <ul> <li>“Precondition: expand your adjacent possible”</li> <li>“Set your filters on ‘important problems’”, “Investigate failures/annoyances”, “Use analogies”, and “Challenge the status quo”</li> </ul> </li> <li><a href="https://medium.com/@marcotcr/organizing-and-evaluating-research-ideas-e137637b599e">Organizing and evaluating research ideas</a> by Marco Tulio Ribeiro <ul> <li>The Checklist/template for Organizing and Evaluating Research Ideas is very helpful!</li> </ul> </li> <li><a href="https://medium.com/great-research/finding-and-proposing-a-ph-d-dissertation-topic-6bca29253a0f">Finding and proposing a PhD dissertation</a> topic by Nick Feamster</li> <li><a href="https://web.archive.org/web/20190421034536/https://medium.com/the-mission/a-genius-explains-how-to-be-creative-claude-shannons-long-lost-1952-speech-fbbcb2ebe07f">Claude Shannon’s “creative thinking” speech</a> by Jimmy Soni</li> </ul> <h2 id="academic-writing">Academic writing</h2> <ul> <li><a href="https://greatresearch.org/2013/10/11/storytelling-101-writing-tips-for-academics/">Storytelling 101: Writing Tips for Academics</a> by Nick Feamster.</li> <li><a href="https://www.microsoft.com/en-us/research/academic-program/write-great-research-paper/">How to Write a Great Research Paper</a> by Simon Peyton Jones. * <ul> <li><strong>Writing papers is a primary mechanism for doing research (not just for reporting it)</strong> I am so surprised that I didn’t know this before. So let’s try to write while doing research!!</li> </ul> </li> <li><a href="https://press.uchicago.edu/ucp/books/book/chicago/C/bo23521678.html">The Craft of Research, Fourth Edition</a>(You can download it from the <a href="https://libgen.is">Library genesis</a>)</li> <li><a href="https://medium.com/@marcotcr/writing-part-1-the-process-6bb92cb522eb">Writing, part 1 — the process</a> by Marco Tulio Ribeiro</li> </ul> <h2 id="presentation">Presentation</h2> <ul> <li><a href="https://www.microsoft.com/en-us/research/academic-program/give-great-research-talk/">How to give a great research talk</a> by Simon Peyton Jones <ul> <li>I will read the slides whenever I need to prepare for a talk! It’s an <strong>amazing talk</strong> about how to give a great talk.</li> </ul> </li> <li><a href="http://graphics.stanford.edu/~kayvonf/misc/cleartalktips.pdf">Tips for giving clear talks</a> by Kayvon Fatahalian <ul> <li><strong>Twelve Important tips</strong> and also provide examples for each tip.</li> </ul> </li> <li><a href="https://docs.google.com/document/d/1gkUWgYMQ37kJ-Bu4wmcEi7x30ZEnmRw99ZMSUhZcQtI/edit">Creating an effective poster</a> by John Wilkes <ul> <li>There are many concrete tips to create a good poster.</li> </ul> </li> <li><a href="https://www.youtube.com/watch?v=Unzc731iCUY">How to speak</a> by Patrick Winston</li> <li><a href="https://homes.cs.washington.edu/~mernst/advice/giving-talk.html">How to give a technical presentation</a> by Mike Ernst</li> <li><a href="https://youtu.be/SYk29tnxASs">How to create a better research poster in less time</a> by Mike Morrison <ul> <li>An <strong>amazing</strong> video with many examples and high-level principles. Highly recommend it!!</li> </ul> </li> </ul> <h2 id="coding">Coding</h2> <ul> <li><a href="https://goodresearch.dev">The Good Research Code Handbook</a> by Patrick J Mineault. <ul> <li><strong>Highly Recommended</strong> I really like the opinion <strong>writing good research code is about freeing your memory</strong></li> </ul> </li> </ul> <h2 id="中文总结">中文总结</h2> <p>Other people’s stories are counterfactual worlds for us.</p> <p>这一节主要是一些前人前辈的读博总结（也有工作之后的总结），<strong>常读常新</strong>。</p> <ul> <li> <p><a href="https://www.zhihu.com/column/yuandong">知乎专栏 远东轶事 - 田渊栋</a> 记录了挺多田渊栋的杂谈类文章，下面是几篇看过的，最有收获的</p> <ul> <li><a href="http://yuandong-tian.com/five_year_summary_of_PhD.pdf">博士五年总结系列</a> 里面讲述了读博五年的一些经验教训，包括怎么写作，怎么 present，怎么时间管理，以及在学习过程中心态的变化和成长，非常值得一读！</li> <li>博士五年之后五年的总结包括工作之后的一些心路历程和思考也值得一读！ <ul> <li><a href="https://zhuanlan.zhihu.com/p/45695338">前言</a>, <a href="https://zhuanlan.zhihu.com/p/45703402">其一</a>, <a href="https://zhuanlan.zhihu.com/p/45898250">其二</a>, <a href="https://zhuanlan.zhihu.com/p/46760428">其三</a>, <a href="https://zhuanlan.zhihu.com/p/47840442">终篇</a></li> </ul> </li> </ul> </li> <li><a href="https://zhuanlan.zhihu.com/p/338193330">计算机视觉 哥大读博五年总结 by Mike Shou</a> 比较详细记录了博士生涯的心路历程和成长，特别是提到了一些踩过的坑（包括和 advisor 的交流，research 相关的思考）</li> <li><a href="https://zhuanlan.zhihu.com/p/25099638">博士这五年 - 李沐</a> 相对而言有更多的 research 细节，但是同样有五年中的读博感想，很有启发。很喜欢最后一句话 <em>“更重要的是理想和情怀。人一生要工作五十年，为什么不花五年来追求下理想和情怀呢？”</em>。 另外沐神的 B 站账号<a href="https://space.bilibili.com/1567748478/">跟李沐学 AI</a> 也超级棒！</li> <li><a href="https://zhuanlan.zhihu.com/p/374777591">工作五年反思 - 李沐</a> 集中分享了工作之后经验和感悟，和读博期间还挺不一样的。</li> <li><a href="https://zhuanlan.zhihu.com/p/357353090">YY 硕 博士第三年</a> 因为 YY 硕 是做 Robotic 的，所以有很多是这方面的，但是很重要的一点是，读博前强如 YY 硕，还是在第一二年感到痛苦，甚至有退学的情绪。</li> </ul> <h2 id="video--podcast">Video &amp; Podcast</h2> <ul> <li><a href="https://www.youtube.com/channel/UCjWnhn8mmA3DEEHlniCEoXA/videos">我在纽约当教授 - TT YaYa YouTube Channels</a> 非常棒的一个视频频道，为数不多的生活向学术频道，学习到了超级多（包括怎么读博，美国 funding system，教职相关的经验等等）！ TT YaYa 和摄影师太有意思啦！强力推荐！！具体的一些 video 大家可以自己挖掘~</li> <li><a href="https://www.youtube.com/channel/UC1PCPgKxjsK6P-po9DlBpQQ/videos">Acsic People</a> 干货浓度非常高！ <a href="https://youtu.be/gNkCcoJUJ-I">Two-body problem</a>, <a href="https://youtu.be/lOOBJix9-Dw">What My Mentors Taught Me</a>, <a href="https://youtu.be/KTcu33RghQs">前车之鉴</a> 等等都非常精彩！</li> <li><a href="https://podcast.gv.com">Theory and Practice</a></li> <li><a href="https://night-science.org/the-night-science-podcast/">Night Science</a></li> <li><a href="https://www.lidingzeyu.com/podcast/">李丁聊天室播客</a></li> </ul> <h2 id="resources">Resources</h2> <ul> <li><a href="https://courses.cs.washington.edu/courses/cse590x/22wi/">The Tao of PhD at UW</a>. Most of the above articles are from this seminar. Thanks a lot, Anna Karlin, Mike Ernst and Pratyush Patel!</li> <li><a href="https://matt.might.net/articles/">“Graduate school”, “Productivity”, “Writing”, and “Giving presentations”</a> by Matthew Might</li> <li><a href="https://www.cs.cmu.edu/~jasonh/advice.html">Advice for research students</a> by Jason Eisner</li> <li><a href="https://www.cs.virginia.edu/~evans/advice/">Dave’s advice collection</a> by David Evans</li> </ul>]]></content><author><name>Xinming Tu</name></author><summary type="html"><![CDATA[Collection of some resources related to the PhD journey.]]></summary></entry><entry><title type="html">Seurat CCA? It’s just a simple extension of PCA!</title><link href="https://xinmingtu.github.io/blog/2022/CCA_dual_PCA/" rel="alternate" type="text/html" title="Seurat CCA? It’s just a simple extension of PCA!"/><published>2022-02-05T23:00:00+00:00</published><updated>2022-02-05T23:00:00+00:00</updated><id>https://xinmingtu.github.io/blog/2022/CCA_dual_PCA</id><content type="html" xml:base="https://xinmingtu.github.io/blog/2022/CCA_dual_PCA/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>The canonical correlation analysis (CCA) implemented as part of Seurat software package is one of the most popular methods for batch effects correction in single-cell RNA-seq datasets. However, the <em>Method</em> part of the original paper<a href="https://doi.org/10.1016/j.cell.2019.05.031"> Comprehensive Integration of Single-Cell Data</a> is not easy to read. After carefully reading the math, and also doing some experiments, my friend (Ziyu Chen) and I realized that the math behind the so-called CCA method actually is better described by the dual form of PCA (“dual PCA” for short). This understanding provides more clarity into the objective function solved by the “Seurat CCA algorithm” and also, as I describe later, provides some insights to improve it.</p> <p>In this blog,</p> <ul> <li> <p>I will first introduce PCA and dual PCA. While PCA/dual PCA computes the self-similarity in one dataset (\(XX^T\)), we can extend them to compute the similarity across two datasets (\(XY^T\)), and this is equivalent to “Seurat CCA”!</p> </li> <li> <p>Importantly, this derivation clarifies that “Seurat CCA” is missing the multiplication with singular values in the embedding process that dual PCA implies. We demonstrated by experiments that if the singular values are considered (as they should be), more biological variation will be preserved.</p> </li> <li> <p>Finally, it’s not difficult to show that there is an intrinsic connection between the two most popular batch-effect removing methods, namely “Seurat CCA” and MNN (Mutual nearest neighbor).</p> </li> </ul> <h2 id="principal-components-analysis-pca">Principal Components Analysis (PCA)</h2> <p>PCA is a very popular method for dimension reduction.</p> <h3 id="direct-pca">Direct PCA</h3> <p>PCA aims to project data points \(x \in R^{g}\) into a linear subspace \(R^k\) while preserving as much as variability as possible.</p> <p>For a given dataset \(X\in R^{n \times g}\) (In single cell RNAseq data, \(n\) is the number of cells, \(g\) is the number of genes), PCA finds a linear embedding \(Z= XV \in R^{k \times n}\), where \(X\in R^{n\times g}, V\in R^{g \times k}\), to represent \(X\) while preserving as much as possible the variability in \(X\). (<em>Note: An equivalent and another common definition of PCA is the projection onto a subspace minimizing the squared reconstruction error.</em>)</p> <p>The solution \(V\) can be calculated from the singular value decomposition (SVD) of \(X\):</p> \[X = U\Sigma V^T, X^TX=V \Sigma^2 V^{T}.\] <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-06-09-41-51-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-06-09-41-51-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-06-09-41-51-1400.webp"/> <img src="/assets/img/2022-02-06-09-41-51.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>\(X\in R^{n\times g}\) is the gene-gene expression matrix. \(X^TX \in R^{g\times g}\) are the gene co-variance matrix. Equivalently put, the SVD provides the best low rank approximation of gene-gene co-variance matrix as the multiplication of top \(K\) singular values and vectors of \(X\) shown below:</p> <hr/> <p>And the embedding we are looking for in PCA will be</p> \[Z = XV_{1:g, 1:k} =U\Sigma V^T V_{1:g,1:k} = U_{1:n, 1:k}\Sigma_{1:k}.\] <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-06-09-55-33-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-06-09-55-33-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-06-09-55-33-1400.webp"/> <img src="/assets/img/2022-02-06-09-55-33.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>\(Z_X \in R^{n\times k}\) is the low dimensional embeddings. } \(The V^{'T} \in R^{g\times k}\) is the project matrix.Then based on the SVD, \(Z = U_{1:n, 1:k}\Sigma_{1:k}\)</p> <hr/> <h3 id="dual-pca">Dual PCA</h3> <p>In the above, SVD was applied to \(X^TX\), which gives us a low rank approximation to the full gene-gene covariance matrix. But what if we apply SVD to \(XX^T\)? This would be applying SVD in the “dual space”, which would give us the best low rank approximation to sample-sample covariance matrix</p> \[X = U\Sigma V^T, XX^T=U\Sigma^2 U^{T}\] <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-06-09-39-43-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-06-09-39-43-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-06-09-39-43-1400.webp"/> <img src="/assets/img/2022-02-06-09-39-43.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>When applying this “dual PCA” to the gene expression matrix as formulated above, The SVD provides the best low rank approximation of cell-cell covariance matrix by select the Top \(k\) singular value and the vectors.</p> <hr/> <p>And \(Z = U_{1:n, 1:k}\Sigma_{1:k}\) will be the embedding, which is the same as what we derived in PCA.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-06-10-13-00-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-06-10-13-00-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-06-10-13-00-1400.webp"/> <img src="/assets/img/2022-02-06-10-13-00.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>\(Z_X \in R^{n\times k}\) is the low dimensional embeddings. Then based on the SVD, \(Z = U_{1:n, 1:k}\Sigma_{1:k}\) is the best embedding which approximate the similarity matrix best.</p> <hr/> <p>We can check it by</p> \[|XX^T - ZZ^T| = |U\Sigma^2 U^{T} - U_{1:n, 1:k}\Sigma_{1:k}^2 (U_{1:n,1:k})^T|.\] <p>Here, the eigenvalues in the diagonal matrix \(\Sigma\) is monotonically decreasing, meaning that \(U_{1:n, 1:k}\Sigma_{1:k}^2 (U_{1:n,1:k})^T\) is the best low-rank approximation of \(U\Sigma^2 U^{T}\).</p> <h2 id="seurat-cca--an-extension-of-dual-pca">“Seurat CCA” – an Extension of Dual PCA</h2> <p>In this section, we will derive an extension of dual PCA and show that it’s almost the same as the “Seurat CCA” method.</p> <p>The dual PCA is formulated to find a low-dimensional embedding while preserving the similarity between samples in one dataset. But how do we apply it to preserve similarities when we have two datasets?</p> <p>More formally, given two datasets(e.g. from two batches), \(X\in R^{n\times g}\) and \(Y\in R^{m\times g}\), where \(n\) and \(m\) means the number of cells, \(g\) means the number of genes. The goal is to find two low-dimensional linear embeddings for both datasets \(Z_X\in R^{n\times k},Z_Y\in R^{m \times k}\) to <strong>preserve the similarity matrix between cells from different datasets rather than in a single dataset</strong>. Mathematically, we can formulate this as follows: we’d like to find an embedding that minimizes the difference between “true” similarity matrix and the similarity of their embedding, \(\|Z_XZ_Y^T - XY^T\|\), which also means finding a low rank approximation of \(XY^T\).</p> <p>Specifying the goal in this way, it may now be more clear that a small modification of dual PCA can solve the for the desired embeddings – In dual PCA, we apply SVD to \(XX^T\), but now we can apply the SVD to \(XY^T\). As <strong>in Dual PCA, the embedding preserves the sample similarity within one dataset, in this new case, the embeddings will preserve the cross-batch sample similarity</strong>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-06-10-22-11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-06-10-22-11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-06-10-22-11-1400.webp"/> <img src="/assets/img/2022-02-06-10-22-11.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>\(X\in R^{n\times g}, Y\in R^{m\times g}\) are the gene expression matrix. \(XX^T \in R^{n\times n}, YY^T \in R^{m\times m}\) are the cell-cell similarity matrixes. \(V_X, V_Y\in R^{g\times k}\) are the project matrix for these two batches. \(Z_X \in R^{n\times k}, Z_Y \in R^{m\times k}\) are the low dimensional embeddings(projection) of two batch data \(X, Y\). The objective function can be written to find these embeddings which preserve the cell-cell similarity matrix as much as possible.</p> <hr/> <p>We can get</p> \[XY^T = U\Sigma V^T\] <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-06-10-31-43-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-06-10-31-43-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-06-10-31-43-1400.webp"/> <img src="/assets/img/2022-02-06-10-31-43.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>The best embeddings will be</p> \[Z_X = U_{1:n,1:k}(\Sigma_{1:k})^\frac{1}{2}, Z_Y = V_{1:n, 1:k}(\Sigma_{1:k})^\frac{1}{2}\] <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-06-10-30-33-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-06-10-30-33-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-06-10-30-33-1400.webp"/> <img src="/assets/img/2022-02-06-10-30-33.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-06-10-30-54-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-06-10-30-54-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-06-10-30-54-1400.webp"/> <img src="/assets/img/2022-02-06-10-30-54.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>\(Z_X \in R^{n\times k}, Z_Y \in R^{m\times k}\) are the best low dimensional embeddings(projection) of two batch data \(X, Y\).</p> <hr/> <p>We can also check this approximation:</p> \[\begin{aligned} |XY^T - Z_XZ_Y^T| &amp;= | U\Sigma V^T - U_{1:n,1:k}\Sigma_{1:k}^\frac{1}{2} (V_{1:n, 1:k}\Sigma_{1:k}^\frac{1}{2})^T| \\ &amp;= | U\Sigma V^T - U_{1:n,1:k}\Sigma_{1:k} (V_{1:m, 1:k})^T| \end{aligned}\] <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-06-10-34-03-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-06-10-34-03-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-06-10-34-03-1400.webp"/> <img src="/assets/img/2022-02-06-10-34-03.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>\(Z_XZ_Y^T\) is the similarity matrix based on the low dimensional embeddings.</p> <hr/> <p>Based on SVD, \(U_{1:n,1:k}\Sigma_{1:k} (V_{1:m, 1:k})^T\) is the best low-rank approximation of \(U\Sigma V^T\).</p> <h2 id="summary-of-math">Summary of Math</h2> <h3 id="dual-pca-1">Dual PCA</h3> <ul> <li><strong>Data</strong>: \(X\in R^{n\times g}\), \(n\) is the number of cells, \(g\) is the number of genes.</li> <li><strong>Task</strong>: \(Z\) to represent the data \(X\).</li> <li><strong>Object</strong>: Minimize \(\|ZZ^T - XX^T\|\) (Dual PCA).</li> <li><strong>Dual PCA Solution</strong>: \(XX^T= U\Sigma^2U^T\), \(Z = U_{1:n,1:g}\Sigma_{1:k}\).</li> </ul> <h3 id="dual-pca-extended-to-two-datasets">Dual PCA Extended to Two Datasets</h3> <ul> <li><strong>Data</strong>: \(X\in R^{n\times g}, Y\in R^{m \times g}\), \(n\) and \(m\) are the number of cells, \(g\) is the number of genes</li> <li><strong>Task</strong>: \(Z_X\in R^{n\times k}\) and \(Z_Y\in R^{m \times k}\) to represent the two datasets \(X\) ane \(Y\).</li> <li><strong>Object</strong>: Minimize \(\|Z_XZ_Y^T - XY^T\|\) .</li> <li><strong>Solution</strong>: \(XY^T = U\Sigma V^T\), \(Z_X = U\Sigma^\frac{1}{2}, Z_Y = V \Sigma^\frac{1}{2}\)</li> </ul> <h2 id="back-to-the-seurat-cca-paper">Back to the “Seurat CCA” paper</h2> <p>In the <em>Method</em> section of the “Seurat CCA” paper, authors had several assumptions to get to the final result of cell embeddings. An important assumption is to “treat the covariance matrix within each dataset as diagonal”, meaning that genes are independent to each other, which is <strong>NOT</strong> true.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-05-20-46-37-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-05-20-46-37-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-05-20-46-37-1400.webp"/> <img src="/assets/img/2022-02-05-20-46-37.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> But it's inconsistent with the biology and not necessary from our view. </div> <p>Alternatively, applying SVD to \(XY^T\) is intuitive and natural - it is just to capture the cell similarity across batches and does not need any assumption.</p> <p>Furthermore, in the original paper, the cell embeddings of two datasets are \(Z_X = U\) and \(Z_Y = V\), is missing the multiplication with the singular value values, as would be implied by SVD application to \(XY^T\)</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-05-19-49-11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-05-19-49-11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-05-19-49-11-1400.webp"/> <img src="/assets/img/2022-02-05-19-49-11.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>From method part of the original paper. In the original paper, \(X\in R^{g\times n}, Y\in R^{g\times m}\), just a different notation.</p> <hr/> <p>To compare the difference in algorithm performance with or without the singular value, we implemented these two methods to data from <a href="https://www.nature.com/articles/s41587-020-0465-8"> Systematic comparison of single-cell and single-nucleus RNA-sequencing methods. Nature biotechnology (2020)</a></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-05-19-57-14-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-05-19-57-14-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-05-19-57-14-1400.webp"/> <img src="/assets/img/2022-02-05-19-57-14.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> After getting the low dimensional embeddings(with/without singular value), we use Umap to visualize the cells from different technologies with the same parameters. And Cells are colored by cell types and batches. </div> <p>As shown in the plot above, when we multiply the embedding by singular values the different cell types are more separated from each other in Umap visualization, meaning that more biological variation is preserved in the embedding.</p> <h3 id="difference-between-seurat-cca-and-real-cca">Difference between “Seurat CCA” and Real CCA</h3> <p>The “Seurat CCA” is taking the projection vector from the traditional CCA directly as cell embeddings. But in fact, <strong>the classical definition of CCA would imply projecting genes into a common space rather than cells.</strong></p> <h2 id="connection-with-the-mutual-nearest-neighbor-mnn-method">Connection with the Mutual Nearest Neighbor (MNN) method.</h2> <p>There is an intrinsic connection between “Seurat CCA” and MNN, another popular method in removing batch-effect.</p> <p>“Seurat CCA” has the assumption that <strong>biologically more similar</strong> cells from different batches have a <strong>higher mathematical similarity</strong> (i.e. the dot product), and similarly, MNN assume similar cells from different batches have <strong>smaller Euclidean distance</strong> defined in the algorithm. In fact, if one standardizes the data (so that each cell has mean of 0 and STD of 1), dot product and euclidean distance are <strong>equivalent</strong>.</p> <p>The above assumptions are clearly observable in “real data”. We can plot a heatmap of the similarity matrix of two different batches, and what we see is a higher similarity along the diagonal.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2022-02-05-20-15-37-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2022-02-05-20-15-37-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2022-02-05-20-15-37-1400.webp"/> <img src="/assets/img/2022-02-05-20-15-37.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The similarity between cells from same cell types is higher than others. </div> <h2 id="conclusion">Conclusion</h2> <ul> <li> <p>Based on our understanding, the math behind the “Seurat CCA” algorithm is technically closer to a dual PCA formulation.</p> </li> <li> <p>In the original paper, the assumption that the covariance matrix of gene expression is diagonal, is not necessary.</p> </li> <li> <p>Furthermore, considering the formulation to preserve the most similarity (dual PCA), the low-dimensional cell embeddings should multiply the singular value, which is currently missing in the “Seurat CCA” algorithm.</p> </li> <li> <p>And finally, there is an intrinsic connection between MNN and “Seurat CCA” (extended dual PCA).</p> </li> </ul> <h2 id="acknowledge">Acknowledge</h2> <p>Thanks for my advisor Sara’s revision and my girl friend Jiahui Peng’s help on the blog writing. Thanks for Ziyu Chen, Zhijie Cao, Weixu Wang’s discussion and comments.</p> <p>If you like this blog, you can give me a like on twitter! Thanks!</p> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Hi all, I want to share my first blog - &quot;Seurat CCA? It&#39;s just a simple extension of PCA!&quot;<a href="https://t.co/K2mUTOkeGT">https://t.co/K2mUTOkeGT</a><a href="https://twitter.com/hashtag/Bioinformatics?src=hash&amp;ref_src=twsrc%5Etfw">#Bioinformatics</a> <a href="https://twitter.com/hashtag/singlecell?src=hash&amp;ref_src=twsrc%5Etfw">#singlecell</a></p>&mdash; Xinming Tu (@TuXinming) <a href="https://twitter.com/TuXinming/status/1513573958376861700?ref_src=twsrc%5Etfw">April 11, 2022</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div>]]></content><author><name></name></author><category term="blog"/><category term="blog,"/><category term="single-cell"/><summary type="html"><![CDATA[Introduction]]></summary></entry></feed>